\chapter{总结与展望}
\label{chap:summary}

\section{全文总结}

本文主要介绍了如何在信息缺失的社交网络中进行社区挖掘。
我们利用局部信息网络的信息学习一个距离度量，通过这个距离度量可以计算所有节点之间的距离，
然后基于这个距离进行聚类，从而达到社区挖掘的目的。
首先我们介绍了社区挖掘所涉及的机器学习方面的背景知识，
包括距离度量和聚类算法两个部分，
其中距离度量是本文提出的距离度量学习算法的理论基础，而对于各种聚类算法的分析和比较是提出本文提出的基于距离的聚类算法的来源。
接着我们详细讲述了本文所使用的距离度量学习算法DCA，它利用正负语境限制学习一个距离度量，
通过这个距离度量计算出的距离能够保证相似的节点之间距离更近，而不相似的节点之间距离更远。
然后我们详细阐述了本文所使用的基于距离的聚类算法DSHRINK，它是一种层次化聚类方法，
通过不停地迭代把节点聚到一起，直到终止条件被满足，
从而达到社区挖掘的目的。同时，为了加快聚类的速度，我们提出了一种近似的手段，
每轮迭代把更多的节点聚在一起，从而减少了迭代的次数。
最后，我们通过大量的实验对比我们所提出的算法与kmeans算法在
Blogcatalog数据集上进行社区挖掘的结果,
在实验的过程中，我们解决了如何生成局部信息网络，如何自动化实验和如何评估算法的有效性等一系列的问题。
从\ref{sec:results}可以看出， 本文的算法相对于kmeans算法具有更高的精度，对于信息缺失网络下的社区挖掘具有更高的可靠性和实用性。

\section{存在的问题与解决方法}

\subsection{数据集的选取}

为完成本文的实验，选取的数据集必须要满足以下三个条件：

\begin{enumerate}
\item 挑选出合适的特征作为节点的属性
\item 节点之间存在边用于形成局部信息区域
\item 节点存在标签信息作为事实（Ground Truth）用于评价最后的结果
\end{enumerate}

为了得到这样的数据集，我们首先尝试使用新浪微博的数据进行实验，使用Python语言实现了一个爬取新浪微博数据的
\href{https://github.com/chouqin/weibo-crawler}{爬虫},
该爬虫能够爬取用户的微博，资料以及用户之间互相关注的信息。
同时，通过NLPIR分词库对用户的微博的进行分词，提取用户的关键字作为用户的属性。
但是由于新浪微博的限制，爬取大量用户的微博很难实现，而且新浪微博没有哪些用户的社区信息，
缺少这个信息就不能对算法进行评价，所以决定采取其他的数据集进行实验。

然后先后尝试了Google+, Facebook，Twitter的数据集，但都因为数据量不够而放弃使用。
接着又尝试了Flixter的数据集用于实验，可是它没有Ground Truth，只好放弃。最终选定了论文用于实验的Blogcatalog的数据集，
它能满足上述三点要求。

\subsection{信息缺失网络的构成}

由社交网络信息产生的数据集需要进行以下两个步骤才能转化为实验需要的信息缺失网络：

\begin{enumerate}
\item 由于从社交网络抓取到的数据比较多，需要对抓取的数据集进行采样，选取适量个数的节点。
在选取的时候，利用节点的类信息，选取几个数目差不多的类，然后选取属于这几个类的节点作为样本。
具体的取样过程见\ref{sec:imple:dataset}。
\item 由于取样的数据集并不大，可以得到所有节点完整的信息。
为了得到一个信息缺失的网络，可以随机地生成几个局部信息网络，
然后只保留这几个局部信息网络的信息。生成局部信息网络的方法如下：
随机选取一个没有在任何局部信息网络中的节点，然后利用宽度优先搜索添加节点到当前的局部信息网络，
直到达到指定的个数为止。
\end{enumerate}


\subsection{属性的选取}

在选取了特定的节点之后，要生成合适的属性信息用于计算节点之间的距离。
因为数据集中的节点的属性是稀疏的（也就是说，节点大部分的属性值都是0），
有必要对属性进行一定的处理。本文采用PCA进行特征提取。具体请看\ref{sec:imple:dataset}。

\subsection{中间结果的验证}

因为整个算法分为两步，必须要确保第一步结果的正确才能开始第二步的实验。
为验证距离学习的正确性，
我们实现了谱聚类算法，
通过对比谱聚类算法在第一步学习到的马氏距离和原来的欧式距离上的结果，
如果马氏距离的结果优于欧式距离，则说明第一步正确。

\subsection{DSHRINK算法的实现}

在用DSHRINK算法进行聚类时，发现聚类的结果不是很好，
一个经常出现的情况是大部分的节点都被聚到了一个聚类，
而其他聚类的节点个数则非常少，经过反复的实验，发现可以从以下几个方面进行改进：

\begin{enumerate}
\item 每次在挑选节点组成当地社区（Local community）时，对节点的所有近似最近节点按照和节点的距离进行排序，
然后按照距离从小到大进行选取。
\item 每次把一个local community合并成一个超级节点时，需要重新计算这个超级节点和其他节点之间的距离，
可以按照需要选取local community中所有节点距离的最小值，最大值和平均值作为超级节点的距离。
\end{enumerate}

\section{未来展望}

由于作者研究能力有限，经验不足，而且研究时间有限，本文提出的算法还有一些可以改善的空间：

首先，在数据选取方面，本文采用的两组实验数据都来自于Blogcatalog的数据集。如果具有更多的时间，仍然可以尝试使用其他的数据集进行实验。同时，在时间允许的情况下，本文实现的新浪微博爬虫也可以得到更多的改进，用于抓取有用的数据。

其次，在学习距离度量时，现在有很多的距离度量学习算法，本文只使用了DCA算法用于学习距离度量，
如果条件允许，可以实现多种度量学习算法对比实验结果，然后选取其中最好的度量学习算法。

最后，在进行实验时，由于算法具有一定的随机性，对于不同的条件，重复执行5次求得实验结果。如果有足够的时间，应该重复更多的次数，这样结果会更加准确。
